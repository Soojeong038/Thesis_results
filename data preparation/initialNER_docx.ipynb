{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd66c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from extractText_docx.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sooje\\anaconda3\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from extractText_docx import extract_text\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRuler \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3b0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download de_core_news_lg\n",
    "nlp = spacy.load('de_core_news_lg')\n",
    "\n",
    "#add hand-craft rules : MA ##, Stadt~ Wien\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before = 'ner')\n",
    "\n",
    "patterns = [\n",
    "                {\n",
    "                    \"label\": \"ORG\", \"pattern\": [\n",
    "                        {\"TEXT\": {\"REGEX\": r\"MA\"}},\n",
    "                        {\"TEXT\": {\"REGEX\": r\"\\w\\d+\"}}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"ORG\", \"pattern\": [\n",
    "                        {\"TEXT\": {\"REGEX\": r\"Magistratsabteilung\"}},\n",
    "                        {\"TEXT\": {\"REGEX\": r\"\\w\\d+\"}}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"ORG\", \"pattern\": [\n",
    "                        {\"TEXT\": {\"REGEX\": r\"Stadt*\"}},\n",
    "                        {\"TEXT\": {\"REGEX\": r\"\\w\"}},\n",
    "#                         {\"TEXT\": {\"REGEX\": r\"Wien\"}},\n",
    "                    ]\n",
    "                }  \n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# #create the doc\n",
    "# doc = nlp(text)\n",
    "\n",
    "# #extract entities\n",
    "# for ent in doc.ents:\n",
    "#     print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213b3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSONL format : {\"text\": \"President Obama\", \"labels\": [ [10, 15, \"PERSON\"] ]}\n",
    "\n",
    "def ner(nlp, file, text, doc_id):\n",
    "    '''text = paragraphs list'''\n",
    "    ner_init = [] #save inital NER\n",
    "#     ner_init.append({\"text\":'Start of document - file: {}'.format(file), \"label\":''})\n",
    "    para_id = 0\n",
    "    for i in text:\n",
    "        doc=nlp(i)\n",
    "        labels_list=[] #save labels\n",
    "        \n",
    "        for word in doc.ents:\n",
    "            if word.label_ == \"ORG\": #only organisations\n",
    "                labels_list.append([word.start_char, word.end_char, word.label_])\n",
    "        \n",
    "#         if len(labels_list) > 0:\n",
    "        ner_init.append({\"text\":i, \"label\":labels_list, \"doc_id\":doc_id, \"para_id\":para_id})\n",
    "        para_id += 1\n",
    "    return ner_init   \n",
    "\n",
    "\n",
    "def export_jsonl(save_path,file_name,ner_init):\n",
    "    file = save_path + '\\\\' + file_name + '.jsonl'\n",
    "    with open(file, 'w') as fp:\n",
    "        for i in ner_init:\n",
    "            json.dump(i, fp)\n",
    "            fp.write('\\n')\n",
    "    fp.close()\n",
    "    print('Successfully exported : ', file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea39567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from docx...\n",
      "MA 57, Maßnahmenbekanntgabe zu MA 57, MA 17 und Verein PEREGRINA - Bildungs-, Beratungs- und Therapiezentrum für Immigrantinnen, Prüfung des Vereines PEREGRINA\n",
      "Finding named entities...\n",
      "Exporting...\n",
      "Successfully exported :  C:\\Users\\sooje\\StRH-I-3-20-MA_57.docx.jsonl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    doc_id = 0\n",
    "    path = 'StRH-I-3-20-MA_57.docx'\n",
    "    print('Extracting text from docx...')\n",
    "    file = extract_text(path)\n",
    "    extracted_paragraphs = file.clensing()\n",
    "    print(file.title)\n",
    "    \n",
    "    print('Finding named entities...')\n",
    "    ner_init = ner(nlp, path, extracted_paragraphs, doc_id)\n",
    "    \n",
    "    print('Exporting...')\n",
    "    export_jsonl('C:\\\\Users\\\\sooje',path, ner_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
